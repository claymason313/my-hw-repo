---
title: "Mason, Clay HW 1 - Try 2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


# STA 380, Part 2: Exercises 1
# Part A.
Random_choser =.3
truthful_choser= .7
Random_choser_no = .5
Random_choser_yes = .5

Total_yes = .65
Total_no = .35

truthful_choser_yes = (Total_yes - (Random_choser_yes*Random_choser))/ (truthful_choser)


'(.5 x .3)+(.7 x truthful_choser_yes)=.65")'

truthful choosers who answered 'yes' represent 5/(5+2) or 71% of the Truthful population


```{r,echo = FALSE}
rm(list=ls())
Random_choser =.3
truthful_choser= .7
Random_choser_no = .5
Random_choser_yes = .5

Total_yes = .65
Total_no = .35

truthful_choser_yes = (Total_yes - (Random_choser_yes*Random_choser))/ (truthful_choser)
truthful_choser_yes

truthful_choser_no = 1 - truthful_choser_yes
truthful_choser_no
print("Overall probabability table is shown below")

prob_problem = matrix(c(15,50,15,20), ncol=2)
colnames(prob_problem) <- c('Yes', 'No')
rownames(prob_problem) <- c('Random', 'Truthful')
prob_problem.table <- as.table(prob_problem)
prob_problem.table



print("(.5*.3)+(.7*truthful_choser_yes)=.65")
print(truthful_choser_yes)
print("truthful choosers who answered 'yes' represent 5/(5+2) or 71% of the Truthful population")
```




# Part B.#
```{r,echo = FALSE}
rm(list=ls())

  
print("Seeking true_positives_P(D|PT). Find PT first")

sensitivity = 0.993 #P(PT|D)
specificity = 0.9999 #P(NT|ND)
Disease = 0.000025 #P(D)
No_Disease = (1-Disease) #P(ND)
No_Disease
false_positives = (1-specificity) #P(PT|ND)

Positive_Test = (sensitivity * Disease) + (false_positives*No_Disease) #P(PT)
Positive_Test

true_positives = sensitivity*Disease / Positive_Test #P(D|PT) 
true_positives


```
sensitivity  = true_positives / (true_positives + false_negatives) #P(PT|D)
specificity = true_negatives / (true_negatives + false_positives) #P(NT|ND)
Negative_Test  = #P(NT)
true_negatives  = #P(ND|NT)
true_positives = #P(D|PT)
false_negatives = #P(NT|D)
false_positives = #P(PT|ND)
```
 
```{r,echo = FALSE}
print("Suppose someone tests positive. What is the probability that they have the disease? 
In light of this calculation, do you envision any problems in implementing a 
universal testing policy for the disease?")

print("Given that someone tests positive on the test, there is approximately 19.88%
chance that the person will have the disease. The odds are pretty low. Depending on the disease and treatment, 
it could be detrimental to treat a healthy person")
```

# Exploratory analysis: green buildings 

```{r,echo = FALSE}

library(mosaic)

green = read.csv('greenbuildings.csv')
summary(green)

# Extract the buildings with green ratings#
green_only = subset(green, green_rating==1)
dim(green_only)

# Not a normal distribution at all#
hist(green_only$Rent, 25)
mean(green_only$Rent)

# Normal-based confidence interval for the sample mean #
xbar = mean(green_only$Rent)
sig_hat = sd(green_only$Rent)
se_hat = sig_hat/sqrt(nrow(green_only))
xbar + c(-1.96,1.96)*se_hat

# Using R's lm function
model1 = lm(Rent ~ 1, data=green_only)
confint(model1, level=0.95)


 # Compare with bootstrapping  #

 # a single bootstrapped sample (repeat a few times) #
green_only_boot = resample(green_only)
mean(green_only_boot$Rent)

 # Get a feel for what it is in the green_only_boot object  #
head(green_only_boot)

 # Now repeat 2500 times  #
boot1 = do(2500)*{
  mean(resample(green_only)$Rent)
}
head(boot1)
hist(boot1$result, 30)
sd(boot1$result)

# Extract the confidence interval from the bootstrapped samples  #
confint(boot1, level=0.95)
xbar + c(-1.96,1.96)*se_hat



 # Bootstrap the median #
median(green_only$Rent)

 # Now repeat 2500 times  #
boot2 = do(2500)*{
  median(resample(green_only)$Rent)
}
head(boot2)

# Ugly!
hist(boot2$result, 30)

# But we still get a confidence interval
confint(boot2)
```

# Bootstrapping Finance Problem

```{r,echo = FALSE}

rm(list=ls())

library(mosaic)
library(quantmod)
library(foreach)

# Import a few stocks #
mystocks = c("SPY", "TLT", "LQD","EEM","VNQ")
getSymbols(mystocks, from = "2005-01-01")

# Adjust for splits and dividends #

for(ticker in mystocks) {
  expr = paste0(ticker, "a = adjustOHLC(", ticker, ")")
  eval(parse(text=expr))
}

# Look at close-to-close changes #

plot(ClCl(SPYa))
plot(ClCl(TLTa))
plot(ClCl(LQDa))
plot(ClCl(EEMa))
plot(ClCl(VNQa))

# make sure we have returns for the full sample. 2005 was firt year for all 5 indices to have their returns published #
head(SPYa)
head(TLTa)
head(LQDa)
head(EEMa)
head(VNQa)



# Combine close to close changes in a single matrix #
all_returns = cbind(
  ClCl(SPYa), 
  ClCl(TLTa), 
  ClCl(LQDa), 
  ClCl(EEMa), 
  ClCl(VNQa)
  )


head(all_returns,2)
all_returns = as.matrix(na.omit(all_returns))







# These returns can be viewed as draws from the joint distribution #
# Compute the returns from the closing prices #
pairs(all_returns)




print ("Look at the market/S&P 500 returns over time")
print ("Annual Standard Deviation: ") 
sd(all_returns[,1])*sqrt(250)
plot(all_returns[,1], type='l')






print ("Look at US Treasury bonds (TLT) returns over time")
print ("Annual Standard Deviation: ") 
sd(all_returns[,2])*sqrt(250)
plot(all_returns[,2], type='l')







print ("Look at Investment-grade corporate bonds (LQD)returns over time")
print ("Annual Standard Deviation: ") 
sd(all_returns[,3])*sqrt(250)
plot(all_returns[,3], type='l')








print ("Look at the Emerging-market equities (EEM) returns over time")
print ("Annual Standard Deviation: ") 
sd(all_returns[,4])*sqrt(250)

plot(all_returns[,4], type='l')




print ("Look at the	Real estate (VNQ) returns over time")
print ("Annual Standard Deviation: ") 
sd(all_returns[,5])*sqrt(250)
plot(all_returns[,5], type='l')



print ("The sample correlation matrix")
print (cor(all_returns))





print("Sample a random return from the empirical joint distribution")
print("one day analysis - event weighting")
#"This simulates a random day"
return.today = resample(all_returns, 1, orig.ids=FALSE)
print("random return today =")
print(return.today)

# Update the value of your holdings
# Assumes an equal allocation to each asset
total_wealth = 100000
my_weights = c(0.2,
               0.2,
               0.2, 
               0.2, 
               0.2)
holdings = total_wealth*my_weights
holdings = holdings*(1 + return.today)

# Compute your new total wealth
total_wealth = sum(holdings)
sum(holdings)





print("two trading week simulation")
total_wealth_2 = 100000
weights_2 = c(0.2, 
            0.2, 
            0.2, 
            0.2, 
            0.2)
holdings_2 = weights_2 * total_wealth_2
n_days_2 = 10
wealthtracker_2 = rep(0, n_days_2) # Set up a placeholder to track total wealth
for(today in 1:n_days_2) {
  return.today = resample(all_returns, 1, orig.ids=FALSE)
  holdings_2 = holdings_2 + holdings_2*return.today
  total_wealth_2 = sum(holdings_2)
  wealthtracker_2[today] = total_wealth_2
}
print("Total Wealth")
total_wealth_2
plot(wealthtracker_2, type='l')






# Even Split Portfolio #
print ("simulate many different possible scenarios over a one year period")
print ("Even Split Portfolio")
initial_wealth_even = 100000
sim_even = foreach(i=1:5000, .combine='rbind') %do% {
  total_wealth_even = initial_wealth_even
  weights_even = c(0.2, 
              0.2, 
              0.2, 
              0.2, 
              0.2)
  holdings_even = weights_even * total_wealth_even 
  n_days_even = 250
  wealthtracker_even= rep(0, n_days_even)
  for(today in 1:n_days_even) {
    return.today = resample(all_returns, 1, orig.ids=FALSE)
    holdings_even = holdings_even + holdings_even*return.today
    total_wealth_even = sum(holdings_even)
    wealthtracker_even[today] = total_wealth_even
  }
  wealthtracker_even
}

head(sim_even,2)
hist(sim_even[,n_days_even], 25)

 # Profit/loss #
mean(sim_even[,n_days_even])
hist(sim_even[,n_days_even] - initial_wealth_even, breaks=30)

print(" 5% value at risk for 20 days")
quantile(sim_even[,20], 0.05) - initial_wealth_even
Var_even = initial_wealth_even - quantile(sim_even[,20], 0.05)
print(Var_even)






 # aggressive #
spy_w_a = .40
tlt_w_a = .05
lqd_w_a = .05
eem_w_a = .30
vnq_w_a = .4

print(cat(paste("Aggressive Split Portfolio", 
         "US domestic equities (SPY: the S&P 500 stock index)", spy_w_a, 
         "US Treasury bonds (TLT)",tlt_w_a,
        "Investment-grade corporate bonds (LQD)",lqd_w_a,
        "Emerging-market equities (EEM)",eem_w_a,
        "Real estate (VNQ)", vnq_w_a
          ,sep="\n")))



initial_wealth_aggressive = 100000
sim_aggressive = foreach(i=1:5000, .combine='rbind') %do% {
  total_wealth_aggressive = initial_wealth_aggressive
  weights_aggressive = c(spy_w_a, 
                         tlt_w_a, 
                         lqd_w_a, 
                         eem_w_a, 
                         vnq_w_a)
  holdings_aggressive = weights_aggressive * total_wealth_aggressive 
  n_days_aggressive = 250
  wealthtracker_aggressive= rep(0, n_days_aggressive)
  for(today in 1:n_days_aggressive) {
    return.today = resample(all_returns, 1, orig.ids=FALSE)
    holdings_aggressive = holdings_aggressive + holdings_aggressive*return.today
    total_wealth_aggressive = sum(holdings_aggressive)
    wealthtracker_aggressive[today] = total_wealth_aggressive
  }
  wealthtracker_aggressive
}

head(sim_aggressive,2)
hist(sim_aggressive[,n_days_aggressive], 25)

 # Profit/loss  #
mean(sim_aggressive[,n_days_aggressive])
hist(sim_aggressive[,n_days_aggressive] - initial_wealth_aggressive, breaks=30)

print(" 5% value at risk for 20 days")
quantile(sim_aggressive[,20], 0.05) - initial_wealth_aggressive
Var_aggressive = initial_wealth_aggressive - quantile(sim_aggressive[,20], 0.05)
print(Var_aggressive)





 # conservative #
spy_w_c = .05
tlt_w_c = .40
lqd_w_c = .40
eem_w_c = .05
vnq_w_c = .10

print(cat(paste("Conservative Split Portfolio", 
                "US domestic equities (SPY: the S&P 500 stock index)", spy_w_c, 
                "US Treasury bonds (TLT)",tlt_w_c,
                "Investment-grade corporate bonds (LQD)",lqd_w_c,
                "Emerging-market equities (EEM)",eem_w_c,
                "Real estate (VNQ)", vnq_w_c
                ,sep="\n")))

initial_wealth_conservative = 100000
sim_conservative = foreach(i=1:5000, .combine='rbind') %do% {
  total_wealth_conservative = initial_wealth_conservative
  weights_conservative = c(spy_w_c, 
                         tlt_w_c, 
                         lqd_w_c, 
                         eem_w_c, 
                         vnq_w_c)
  holdings_conservative = weights_conservative * total_wealth_conservative 
  n_days_conservative = 250
  wealthtracker_conservative= rep(0, n_days_conservative)
  for(today in 1:n_days_conservative) {
    return.today = resample(all_returns, 1, orig.ids=FALSE)
    holdings_conservative = holdings_conservative + holdings_conservative*return.today
    total_wealth_conservative = sum(holdings_conservative)
    wealthtracker_conservative[today] = total_wealth_conservative
  }

}

head(sim_conservative,2)
hist(sim_conservative[,n_days_conservative], 25)
plot(wealthtracker_conservative,type = "l",  main = "Conservative Portfolio")

 # Profit/loss  #
mean(sim_conservative[,n_days_conservative])
hist(sim_conservative[,n_days_conservative] - initial_wealth_conservative, breaks=30)

print(" 5% value at risk for 20 days")
quantile(sim_conservative[,20], 0.05) - initial_wealth_conservative
Var_conservative = initial_wealth_conservative - quantile(sim_conservative[,20], 0.05)
print(Var_conservative)



print("# •marshals appropriate evidence to characterize the risk/return properties of the five major asset classes listed above.")




print('# •	outlines your choice of the ""safe"" and ""aggressive"" portfolios.')
print(cat(paste("Aggressive Split Portfolio", 
                "US domestic equities (SPY: the S&P 500 stock index)", spy_w_a, 
                "US Treasury bonds (TLT)",tlt_w_a,
                "Investment-grade corporate bonds (LQD)",lqd_w_a,
                "Emerging-market equities (EEM)",eem_w_a,
                "Real estate (VNQ)", vnq_w_a
                ,sep="\n")))
print("The aggressive portfolio is heavy biased towards equities. Equity biased portfolios have a higher variance/ standard deviation. ")
print(cat(paste("Conservative Split Portfolio", 
                "US domestic equities (SPY: the S&P 500 stock index)", spy_w_c, 
                "US Treasury bonds (TLT)",tlt_w_c,
                "Investment-grade corporate bonds (LQD)",lqd_w_c,
                "Emerging-market equities (EEM)",eem_w_c,
                "Real estate (VNQ)", vnq_w_c
                ,sep="\n")))
print("The more conservative portfolio is primarily invested in treasuries (considered 'risk free') and Investment grade bonds")

print("# •	uses bootstrap resampling to estimate the 4-week (20 trading day) value at risk of each of your three portfolios at the 5% level.")
print("Aggressive")
print(Var_aggressive)
print()
print("Even Weight")
print(Var_even)
print()
print("Conservative")
print(Var_conservative)
print()
print("# •	compares the results for each portfolio in a way that would allow the reader to make an intelligent decision among the three options.")

print("Aggressive Portfolio")
plot(wealthtracker_aggressive,type = "l",  main = "Aggressive Portfolio")
cat("One year total estimate wealth ",tail(wealthtracker_aggressive,n=1))
cat("20 day VAR at 95% confidence", Var_aggressive)
cat("Projected One Year Performance: ",((tail(wealthtracker_aggressive,n=1))-100000)/100000*100,"%")


print("Even Portfolio")
plot(wealthtracker_even,type = "l",  main = "Even Portfolio")
cat("One year total estimate wealth ",tail(wealthtracker_even,n=1))
cat("20 day VAR at 95% confidence", Var_even)
cat("Projected One Year Performance: ",((tail(wealthtracker_even,n=1))-100000)/100000*100,"%")



print("Conservative Portfolio")
plot(wealthtracker_conservative,type = "l",  main = "Conservative Portfolio")
cat("One year total estimate wealth ",tail(wealthtracker_conservative,n=1))
cat("20 day VAR at 95% confidence", Var_conservative)
cat("Projected One Year Performance: ",((tail(wealthtracker_conservative,n=1))-100000)/100000*100,"%")
```



# Market segmentation
```{r,echo = FALSE}
rm(list=ls())
library(tm) 
library(magrittr)
library(corrplot)





social = read.csv('social_marketing.csv', header=TRUE)

attach(social)

#7882 rows and 37 variables



#cut porn 'bots'
#501 with more than one adult. 
#426 with 3 or more
#cut 3 or more in case of error
social_clean1 = social[social["adult"]<3,]
dim(social_clean1)


#cut spam 'bots'
#cut 2 or more in case of error
social_clean2 = social_clean1[social_clean1["spam"]<2,]
# dim(social_clean2)
# social_clean2
summary(social_clean2)
social_clean3 = social_clean2

str(social_clean3)
colnames(social)

#count total amount in each column so we can plot
sum_columns = data.frame(value_columns = apply(social_clean3[,-1],2,sum))
sum_columns$key = rownames(sum_columns)
sum_columns2 = sum_columns[order(-(sum_columns$value)),]

#plot the correlation chart to see any relationships between variables
cor_social_clean3 = cor(social_clean3[,-1]) 
corrplot(cor_social_clean3)



#bar plot to see the most common types
barplot(sum_columns2$value_columns, col = 2,names.arg = sum_columns2$key,xlab="cagegories")

print (sum_columns2$key)

library(ggplot2)
library(LICORS)  # for kmeans++
library(foreach)
library(mosaic)
library(LICORS)
# Center and scale the data
X = social_clean3[,-(1:2)]
X = scale(X, center=TRUE, scale=TRUE)

# Extract the centers and scales from the rescaled data (which are named attributes)
mu = attr(X,"scaled:center")
sigma = attr(X,"scaled:scale")

# Run k-means with 6 clusters and 25 starts
clust1 = kmeans(X, 6, nstart=25)

# What are the clusters?
clust1$center[1,]*sigma + mu
clust1$center[2,]*sigma + mu
clust1$center[3,]*sigma + mu
clust1$center[4,]*sigma + mu
clust1$center[5,]*sigma + mu
clust1$center[6,]*sigma + mu

# Which comments are in which clusters?
which(clust1$cluster == 1)
which(clust1$cluster == 2)
which(clust1$cluster == 3)
which(clust1$cluster == 4)
which(clust1$cluster == 5)

# A few plots with cluster membership shown
# qplot is in the ggplot2 library
qplot(current_events, travel, data=social_clean3, color=factor(clust1$cluster))
qplot(food, family, data=social_clean3, color=factor(clust1$cluster))


# Using kmeans++ initialization
clust2 = kmeanspp(X, k=6, nstart=25)

clust2$center[1,]*sigma + mu
clust2$center[2,]*sigma + mu
clust2$center[4,]*sigma + mu

# Which cars are in which clusters?
which(clust2$cluster == 1)
which(clust2$cluster == 2)
which(clust2$cluster == 3)

# Compare versus within-cluster average distances from the first run
clust1$withinss
clust2$withinss
sum(clust1$withinss)
sum(clust2$withinss)
clust1$tot.withinss
clust2$tot.withinss
clust1$betweenss
clust2$betweenss

```


Below are the groupings I would have assumed without doing a statistical analysis. I wanted to force them into new columsn and see what the data looked like afterwards. 
Arts Grouping: craft, photo_sharing, fashion, art, crafts, beauty, tv_film, music
Hobbies: sports_fandom, sports_playing, online_gaming, computers, automotive, shopping
Home: cooking, food, parenting, home_and_garden, travel, outdoors, dating, family, religion
Health: health_nutrition, personal_fitness
Business and Education: politics, small_business, eco, college_uni, current_events, news, business, school
Random: chatter, spam, adult, uncategorized

